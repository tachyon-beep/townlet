{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PPO Telemetry Quick Look\n",
        "\n",
        "Load PPO NDJSON logs (see `docs/samples/ppo_conflict_telemetry.jsonl`) and plot core metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "LOG_PATH = Path('..') / 'samples' / 'ppo_conflict_telemetry.jsonl'\n",
        "records = [\n",
        "    json.loads(line)\n",
        "    for line in LOG_PATH.read_text().splitlines()\n",
        "    if line.strip()\n",
        "]\n",
        "records[:3]  # peek"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = [float(entry['epoch']) for entry in records]\n",
        "loss_total = [float(entry['loss_total']) for entry in records]\n",
        "kl = [float(entry['kl_divergence']) for entry in records]\n",
        "grad_norm = [float(entry['grad_norm']) for entry in records]\n",
        "reward_sum = [float(entry.get('baseline_reward_sum', 0.0)) for entry in records]\n",
        "rivalry_mean = [float(entry['conflict.rivalry_max_mean_avg']) for entry in records]\n",
        "baseline_reward = [float(entry.get('baseline_reward_sum', 0.0)) for entry in records]\n",
        "epochs, loss_total, kl, grad_norm, rivalry_mean, baseline_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except ModuleNotFoundError:\n",
        "    plt = None\n",
        "\n",
        "if plt is None:\n",
        "    print('matplotlib not available; showing tabular summary instead.')\n",
        "    for epoch, loss, kl_val, grad in zip(epochs, loss_total, kl, grad_norm):\n",
        "        print(f'Epoch {epoch:>3.0f}: loss_total={loss:.4f}, kl_divergence={kl_val:.4f}, grad_norm={grad:.4f}')\n",
        "else:\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(8, 9), sharex=True)\n",
        "    axes[0].plot(epochs, loss_total, marker='o')\n",
        "    axes[0].set_ylabel('loss_total')\n",
        "    axes[1].plot(epochs, kl, marker='o', color='tab:orange')\n",
        "    axes[1].set_ylabel('kl_divergence')\n",
        "    axes[2].plot(epochs, grad_norm, marker='o', color='tab:green')\n",
        "    axes[2].set_ylabel('grad_norm')\n",
        "    axes[2].set_xlabel('epoch')\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Data mode (latest): {records[-1]['data_mode']}\")\n",
        "print(f\"Cycle id (latest): {records[-1]['cycle_id']}\")\n",
        "print(f\"Epoch duration (sec): {records[-1]['epoch_duration_sec']:.4f}\")\n",
        "print(f\"Total reward sum: {reward_sum[-1]:.4f}\")\n",
        "baseline_reward_sum = baseline_reward[-1] if baseline_reward else 0.0\n",
        "print(f'Baseline reward sum (final epoch): {baseline_reward_sum:.4f}')\n",
        "print(f'Rivalry max mean (final epoch): {rivalry_mean[-1]:.4f}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}